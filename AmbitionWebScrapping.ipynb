{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f6a17-077e-4778-8004-5e3121b7e686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "\n",
    "# List of User Agents\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.396',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.4 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/92.0.4515.107 Mobile/15E148 Safari/604.1'\n",
    "]\n",
    "\n",
    "def get_random_user_agent():\n",
    "    return random.choice(user_agents)\n",
    "\n",
    "def make_request(url, max_retries=3, delay=1):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': get_random_user_agent(),\n",
    "                'Accept-Language': 'en-US,en;q=0.9',\n",
    "                'Accept-Encoding': 'gzip, deflate, br',\n",
    "                'DNT': '1',\n",
    "                'Connection': 'keep-alive',\n",
    "                'Upgrade-Insecure-Requests': '1',\n",
    "                'Sec-Fetch-Dest': 'document',\n",
    "                'Sec-Fetch-Mode': 'navigate',\n",
    "                'Sec-Fetch-Site': 'none',\n",
    "                'Sec-Fetch-User': '?1',\n",
    "                'Cache-Control': 'max-age=0'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.RequestException as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            print(f\"Attempt {attempt + 1} failed. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay * (2 ** attempt))\n",
    "    \n",
    "    raise Exception(\"All attempts failed\")\n",
    "\n",
    "# Main execution\n",
    "url = 'https://www.ambitionbox.com/list-of-companies?page=1'\n",
    "try:\n",
    "    webpage = make_request(url)\n",
    "    soup = BeautifulSoup(webpage.content, 'lxml')\n",
    "    print(soup.prettify())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d40961-7c5c-4e83-a463-a5cd05432cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = soup.find_all(\"div\",class_=\"companyCardWrapper\")   #main conatiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90b806a-f020-4ec2-9a62-0a4241d6aa37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95168fe-7514-4a0d-a440-4d1dc817000a",
   "metadata": {},
   "source": [
    "## company name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3fd7c9-10cf-486f-b37e-cc24fc274fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCS\n",
      "Accenture\n",
      "Wipro\n",
      "Cognizant\n",
      "Capgemini\n",
      "HDFC Bank\n",
      "ICICI Bank\n",
      "Infosys\n",
      "HCLTech\n",
      "Tech Mahindra\n",
      "Genpact\n",
      "Teleperformance\n",
      "Concentrix Corporation\n",
      "Axis Bank\n",
      "Amazon\n",
      "Jio\n",
      "Reliance Retail\n",
      "IBM\n",
      "iEnergizer\n",
      "HDB Financial Services\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in soup.find_all(\"h2\"):\n",
    "    print(i.text.strip())\n",
    "    count += 1\n",
    "    if count >= 20:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e5aa2-8a5e-4ecc-bb08-5c1e8f9658db",
   "metadata": {},
   "source": [
    "## Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30d2d0e7-6466-439e-8f95-d521b0edc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all(\"div\",class_=\"rating_text rating_text--md\"):\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77030484-44db-48ab-95a0-69aa5f2aeb64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(soup.find_all(\"span\",class_= \"companyCardWrapper__ActionCount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22faef33-f175-4aff-aff1-cbb16f29a394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf687106-e3b3-4bbb-838d-b43436fa7290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.3k\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all(\"span\",class_= \"companyCardWrapper__ActionCount\")[0]:\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8965881-7a92-466f-8911-6be79baa693e",
   "metadata": {},
   "source": [
    "## Bottom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8afd63d6-1370-43a8-8f41-b05df419c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.3k\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all(\"span\",class_= \"companyCardWrapper__ActionCount\")[0]:\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a42c6db-c2b1-40a8-b321-e508a236e330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.6L\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all(\"span\",class_= \"companyCardWrapper__ActionCount\")[1]:\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e33abf99-285d-4621-97f1-73ff5712d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10k\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all(\"span\",class_= \"companyCardWrapper__ActionCount\")[2]:\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c141d7b9-597c-4951-ba7d-83cf7d3242cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all(\"span\",class_= \"companyCardWrapper__ActionCount\")[3]:\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e9f5469-fc7b-475d-9145-d009ee5fe366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8k\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all(\"span\",class_= \"companyCardWrapper__ActionCount\")[4]:\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73b0f04c-41bb-45d8-929a-480bfbea32e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all(\"span\",class_= \"companyCardWrapper__ActionCount\")[5]:\n",
    "    print(i.text.strip())    #no need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e3fb3-7040-45e5-9cd6-a8206f3c61b3",
   "metadata": {},
   "source": [
    "## creating an empty data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc45264f-eb93-416c-b980-7c9f61b61351",
   "metadata": {},
   "outputs": [],
   "source": [
    "name =[ ]\n",
    "ratings=[]\n",
    "reviews = []\n",
    "salaries= []\n",
    "interviews =[]\n",
    "jobs =[]\n",
    "benefits =[]\n",
    "photos=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a312cf2-856d-4fc8-8d93-f92f86d59ff5",
   "metadata": {},
   "source": [
    "## Company Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0406a50e-7fde-4402-926c-da75c3103a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCS\n",
      "Accenture\n",
      "Wipro\n",
      "Cognizant\n",
      "Capgemini\n",
      "HDFC Bank\n",
      "ICICI Bank\n",
      "Infosys\n",
      "HCLTech\n",
      "Tech Mahindra\n",
      "Genpact\n",
      "Teleperformance\n",
      "Concentrix Corporation\n",
      "Axis Bank\n",
      "Amazon\n",
      "Jio\n",
      "Reliance Retail\n",
      "IBM\n",
      "iEnergizer\n",
      "HDB Financial Services\n"
     ]
    }
   ],
   "source": [
    "name = []  \n",
    "\n",
    "count = 0\n",
    "for i in soup.find_all(\"h2\",class_=\"companyCardWrapper__companyName\"):\n",
    "    text = i.text.strip()  \n",
    "    name.append(text)      \n",
    "    print(text)           \n",
    "    count += 1\n",
    "    if count >= 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cba3a7-5f25-4a30-aac1-04898471a386",
   "metadata": {},
   "source": [
    "## Ratings Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "059bfefa-064f-4db9-9a1c-1357cddf063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "ratings = []\n",
    "\n",
    "for i in company:\n",
    "    try:\n",
    "        div_elements = i.find_all(\"div\", class_=\"rating_text rating_text--md\")\n",
    "        if div_elements:\n",
    "            rating_text = div_elements[0].text.strip()\n",
    "            ratings.append(rating_text)\n",
    "        else:\n",
    "            ratings.append(\"\")  # Or some default value\n",
    "    except AttributeError as e:\n",
    "        print(f\"Error processing {i}: {e}\")\n",
    "        ratings.append(\"\")  # Add a default value\n",
    "\n",
    "print(ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d42d9-d827-4a7e-ab73-1c799c02ba00",
   "metadata": {},
   "source": [
    "## Reviews Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bc2d8c9-bfd6-4cf1-a063-d8d918887a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['84.3k', '52.6k', '50.2k', '47.2k', '38.9k', '37.5k', '36.7k', '36.5k', '33.7k', '33.1k', '29.8k', '27.3k', '25k', '24.2k', '23.9k', '21.7k', '21.3k', '21.1k', '20.8k', '19.5k']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "reviews = []\n",
    "\n",
    "containers = soup.find_all(\"div\", class_=\"companyCardWrapper\") \n",
    "\n",
    "for container in containers:\n",
    "    review_count = container.find(\"span\", class_=\"companyCardWrapper__ActionCount\")\n",
    "    if review_count:\n",
    "        reviews.append(review_count.text.strip())\n",
    "\n",
    "print(reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd818ef-73b8-42b1-9182-4587b6913c93",
   "metadata": {},
   "source": [
    "## Salaries Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7c10527-b109-4dc2-a2e0-fa8e90d27d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8.6L', '5.7L', '4.4L', '5.6L', '4.2L', '1.4L', '1.5L', '4.6L', '3.2L', '2.6L', '2L', '89.1k', '1.2L', '98.2k', '1.2L', '62.5k', '66.1k', '2L', '22.1k', '49.6k']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Assuming 'soup' is already created with the HTML content\n",
    "salaries= []\n",
    "\n",
    "containers = soup.find_all(\"div\", class_=\"companyCardWrapper\")  # Replace with actual container class\n",
    "\n",
    "for container in containers:\n",
    "    salaries_count = container.find_all(\"span\", class_=\"companyCardWrapper__ActionCount\")[1]\n",
    "    if salaries_count:\n",
    "        salaries.append(salaries_count.text.strip())\n",
    "\n",
    "print(salaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265cef8-d340-4c37-b8a7-41866cbc73b1",
   "metadata": {},
   "source": [
    "## Interviews Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07478aeb-9bc0-48b7-a4ad-3fd0e20cdcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10k', '7.8k', '5.5k', '5.4k', '4.7k', '2k', '2.4k', '7.4k', '3.6k', '3.7k', '2.9k', '1.7k', '1.6k', '1.4k', '4.9k', '1.6k', '1.5k', '2.3k', '523', '762']\n"
     ]
    }
   ],
   "source": [
    "interviews =[]\n",
    "\n",
    "containers = soup.find_all(\"div\", class_=\"companyCardWrapper\")  # Replace with actual container class\n",
    "\n",
    "for container in containers:\n",
    "    interviews_count = container.find_all(\"span\", class_=\"companyCardWrapper__ActionCount\")[2]\n",
    "    if interviews_count:\n",
    "        interviews.append(interviews_count.text.strip())\n",
    "\n",
    "print(interviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4827b-02d7-4128-8e97-b11349a32bf0",
   "metadata": {},
   "source": [
    "## Jobs Count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fb1c739-278e-4234-a6da-66f0a004348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88', '22.4k', '555', '1.5k', '1.2k', '161', '--', '960', '164', '360', '2.4k', '313', '55', '130', '106', '4.1k', '28', '3.1k', '94', '155']\n"
     ]
    }
   ],
   "source": [
    "jobs =[]\n",
    "containers = soup.find_all(\"div\", class_=\"companyCardWrapper\")  # Replace with actual container class\n",
    "\n",
    "for container in containers:\n",
    "    jobs_count = container.find_all(\"span\", class_=\"companyCardWrapper__ActionCount\")[3]\n",
    "    if jobs_count:\n",
    "        jobs.append(jobs_count.text.strip())\n",
    "\n",
    "print(jobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d876b-1d90-403a-b58a-0e2ca7deeff0",
   "metadata": {},
   "source": [
    "## Benefits Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "314f5e3d-c1d9-4a32-8719-ee92a975dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11.8k', '7.3k', '5.2k', '6k', '4.1k', '3.3k', '3.8k', '5.3k', '4.2k', '3.7k', '3.8k', '2.2k', '3.4k', '2.2k', '4.4k', '2.7k', '2k', '2.8k', '559', '1.6k']\n"
     ]
    }
   ],
   "source": [
    "benefits =[]\n",
    "\n",
    "containers = soup.find_all(\"div\", class_=\"companyCardWrapper\")  # Replace with actual container class\n",
    "\n",
    "for container in containers:\n",
    "    benefits_count = container.find_all(\"span\", class_=\"companyCardWrapper__ActionCount\")[4]\n",
    "    if benefits_count:\n",
    "        benefits.append(benefits_count.text.strip())\n",
    "\n",
    "print(benefits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561b76e-e2c7-4b8c-855d-911118eb9b4e",
   "metadata": {},
   "source": [
    "## Photos Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b2804bd-762f-4ceb-84d3-fdeb47008915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['87', '39', '90', '69', '41', '29', '55', '108', '33', '63', '46', '31', '55', '80', '78', '65', '113', '23', '25', '47']\n"
     ]
    }
   ],
   "source": [
    "photos=[]\n",
    "containers = soup.find_all(\"div\", class_=\"companyCardWrapper\")  # Replace with actual container class\n",
    "\n",
    "for container in containers:\n",
    "    photos_count = container.find_all(\"span\", class_=\"companyCardWrapper__ActionCount\")[5]\n",
    "    if photos_count:\n",
    "        photos.append(photos_count.text.strip())\n",
    "\n",
    "print(photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275dd99c-960b-4192-9e0d-90181e4b481a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344dc13a-d558-46eb-a8a5-a5ead594ed26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b1c73f5-d91e-42a6-9fff-e624f00d2fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed. Retrying in 1 seconds...\n",
      "Attempt 2 failed. Retrying in 1 seconds...\n"
     ]
    }
   ],
   "source": [
    "webpage = make_request(url)\n",
    "if webpage.content is None:\n",
    "    print(f\"No content returned for URL: {url}\")\n",
    "else:\n",
    "    soup = BeautifulSoup(webpage.content, 'lxml')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c03dafee-daf8-4ba6-add5-33dec621533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(webpage.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94ee96c0-f1e1-4985-80ce-80e262575604",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    soup = BeautifulSoup(webpage.content, 'lxml')\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing HTML: {e}\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da13cd91-64a3-4cb4-9fa8-44a7dfdbeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if webpage.content.strip():\n",
    "    soup = BeautifulSoup(webpage.content, 'lxml')\n",
    "else:\n",
    "    print(\"No valid content returned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f7645-0d72-461d-847d-43de55a026d2",
   "metadata": {},
   "source": [
    "## Fetching the first page in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ed116b24-7926-4cdf-b847-d31f13201645",
   "metadata": {},
   "outputs": [],
   "source": [
    "name =[ ]\n",
    "ratings=[]\n",
    "reviews = []\n",
    "salaries= []\n",
    "interviews =[]\n",
    "jobs =[]\n",
    "benefits =[]\n",
    "photos = []\n",
    "\n",
    "for i in company:\n",
    "\n",
    "  name.append(i.find('h2').text.strip())\n",
    "  ratings.append(card.find('div', class_='rating_text rating_text--md').text.strip() if card.find('div', class_='rating_text rating_text--md') else '') \n",
    "  reviews.append(i.find_all('span',class_='companyCardWrapper__ActionCount')[0].text.strip())\n",
    "  salaries.append(i.find_all('span',class_='companyCardWrapper__ActionCount')[1].text.strip())\n",
    "  interviews.append(i.find_all('span',class_='companyCardWrapper__ActionCount')[2].text.strip())\n",
    "  jobs.append(i.find_all('span',class_='companyCardWrapper__ActionCount')[3].text.strip())\n",
    "  benefits.append(i.find_all('span',class_='companyCardWrapper__ActionCount')[4].text.strip())  \n",
    "  photos.append(i.find_all('span',class_='companyCardWrapper__ActionCount')[5].text.strip())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cfe2c-8c88-451e-9d0e-067264155c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f541ae7e-0f7a-425e-b2f1-b33b4b99089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'name':name,\n",
    "   'ratings':ratings,\n",
    "   'reviews':reviews,\n",
    "   'salaries':salaries,\n",
    "   'interviews':interviews,\n",
    "   'jobs':jobs,\n",
    "   'benefits':benefits,\n",
    "   'photos':photos,        \n",
    "   })\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "21a1eb6a-3cb1-4b27-af1d-673ea5fcbd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>salaries</th>\n",
       "      <th>interviews</th>\n",
       "      <th>jobs</th>\n",
       "      <th>benefits</th>\n",
       "      <th>photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>3.4</td>\n",
       "      <td>84.3k</td>\n",
       "      <td>8.6L</td>\n",
       "      <td>10k</td>\n",
       "      <td>88</td>\n",
       "      <td>11.8k</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>3.4</td>\n",
       "      <td>52.6k</td>\n",
       "      <td>5.7L</td>\n",
       "      <td>7.8k</td>\n",
       "      <td>22.4k</td>\n",
       "      <td>7.3k</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wipro</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.2k</td>\n",
       "      <td>4.4L</td>\n",
       "      <td>5.5k</td>\n",
       "      <td>555</td>\n",
       "      <td>5.2k</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3.4</td>\n",
       "      <td>47.2k</td>\n",
       "      <td>5.6L</td>\n",
       "      <td>5.4k</td>\n",
       "      <td>1.5k</td>\n",
       "      <td>6k</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>3.4</td>\n",
       "      <td>38.9k</td>\n",
       "      <td>4.2L</td>\n",
       "      <td>4.7k</td>\n",
       "      <td>1.2k</td>\n",
       "      <td>4.1k</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name ratings reviews salaries interviews   jobs benefits photos\n",
       "0        TCS     3.4   84.3k     8.6L        10k     88    11.8k     87\n",
       "1  Accenture     3.4   52.6k     5.7L       7.8k  22.4k     7.3k     39\n",
       "2      Wipro     3.4   50.2k     4.4L       5.5k    555     5.2k     90\n",
       "3  Cognizant     3.4   47.2k     5.6L       5.4k   1.5k       6k     69\n",
       "4  Capgemini     3.4   38.9k     4.2L       4.7k   1.2k     4.1k     41"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc86d1cc-6164-4cc1-8bde-08a7c3555e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 8)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb28e42-fe2c-4db5-a8e3-7bd7f209017d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3516df15-9a81-4899-a0ee-22d9764fa291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed. Retrying in 1 seconds...\n",
      "Attempt 2 failed. Retrying in 1 seconds...\n",
      "An error occurred while processing page 0: 404 Client Error: Not Found for url: https://www.ambitionbox.com/list-of-companies?page=0\n",
      "Processed page 1\n",
      "Processed page 2\n",
      "Attempt 1 failed. Retrying in 1 seconds...\n",
      "Processed page 3\n",
      "Processed page 4\n",
      "Processed page 5\n",
      "Data collection completed.\n",
      "        name ratings reviews salaries interviews   jobs benefits photos\n",
      "0        TCS     3.7   84.3k     8.6L        10k     88    11.8k     87\n",
      "1  Accenture     3.9   52.6k     5.7L       7.8k  22.4k     7.3k     39\n",
      "2      Wipro     3.7   50.2k     4.4L       5.5k    555     5.2k     90\n",
      "3  Cognizant     3.8   47.2k     5.6L       5.4k   1.5k       6k     69\n",
      "4  Capgemini     3.8   38.9k     4.2L       4.7k   1.2k     4.1k     41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "# User agents\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.396',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.4 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/92.0.4515.107 Mobile/15E148 Safari/604.1'\n",
    "]\n",
    "\n",
    "def get_random_user_agent():\n",
    "    return random.choice(user_agents)\n",
    "\n",
    "def make_request(url, max_retries=3, delay=1):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': get_random_user_agent(),\n",
    "                'Accept-Language': 'en-US,en;q=0.9',\n",
    "                'Accept-Encoding': 'gzip, deflate, br',\n",
    "                'DNT': '1',\n",
    "                'Connection': 'keep-alive',\n",
    "                'Upgrade-Insecure-Requests': '1',\n",
    "                'Sec-Fetch-Dest': 'document',\n",
    "                'Sec-Fetch-Mode': 'navigate',\n",
    "                'Sec-Fetch-Site': 'none',\n",
    "                'Sec-Fetch-User': '?1',\n",
    "                'Cache-Control': 'max-age=0'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.RequestException as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            print(f\"Attempt {attempt + 1} failed. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay * (2 ** attempt))\n",
    "    \n",
    "    raise Exception(\"All attempts failed\")\n",
    "\n",
    "# Main execution\n",
    "for j in range(0, 6):\n",
    "    url = f'https://www.ambitionbox.com/list-of-companies?page={j}'\n",
    "    \n",
    "    try:\n",
    "        webpage = make_request(url)\n",
    "        soup = BeautifulSoup(webpage.content, 'lxml')\n",
    "        \n",
    "        # Find all company cards\n",
    "        company_cards = soup.find_all('div', class_='companyCardWrapper')\n",
    "        \n",
    "        name = []\n",
    "        ratings = []\n",
    "        reviews = []\n",
    "        salaries = []\n",
    "        interviews = []\n",
    "        jobs = []\n",
    "        benefits = []\n",
    "        photos = []\n",
    "        \n",
    "        for card in company_cards:\n",
    "            name.append(card.find('h2').text.strip())\n",
    "            ratings.append(card.find('div', class_='rating_text rating_text--md').text.strip() if card.find('div', class_='rating_text rating_text--md') else '')\n",
    "            reviews.append(card.find_all('span', class_='companyCardWrapper__ActionCount')[0].text.strip() if len(card.find_all('span', class_='companyCardWrapper__ActionCount')) > 0 else '')\n",
    "            salaries.append(card.find_all('span', class_='companyCardWrapper__ActionCount')[1].text.strip() if len(card.find_all('span', class_='companyCardWrapper__ActionCount')) > 1 else '')\n",
    "            interviews.append(card.find_all('span', class_='companyCardWrapper__ActionCount')[2].text.strip() if len(card.find_all('span', class_='companyCardWrapper__ActionCount')) > 2 else '')\n",
    "            jobs.append(card.find_all('span', class_='companyCardWrapper__ActionCount')[3].text.strip() if len(card.find_all('span', class_='companyCardWrapper__ActionCount')) > 3 else '')\n",
    "            benefits.append(card.find_all('span', class_='companyCardWrapper__ActionCount')[4].text.strip() if len(card.find_all('span', class_='companyCardWrapper__ActionCount')) > 4 else '')\n",
    "            photos.append(card.find_all('span', class_='companyCardWrapper__ActionCount')[5].text.strip() if len(card.find_all('span', class_='companyCardWrapper__ActionCount')) > 5 else '')\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'name': name,\n",
    "            'ratings': ratings,\n",
    "            'reviews': reviews,\n",
    "            'salaries': salaries,\n",
    "            'interviews': interviews,\n",
    "            'jobs': jobs,\n",
    "            'benefits': benefits,\n",
    "            'photos': photos\n",
    "        })\n",
    "        \n",
    "        final = pd.concat([final, df], ignore_index=True)\n",
    "        \n",
    "        print(f\"Processed page {j}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing page {j}: {e}\")\n",
    "\n",
    "print(\"Data collection completed.\")\n",
    "print(final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8fae652a-1cd4-45ed-95df-184e9ce776cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>salaries</th>\n",
       "      <th>interviews</th>\n",
       "      <th>jobs</th>\n",
       "      <th>benefits</th>\n",
       "      <th>photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.3k</td>\n",
       "      <td>8.6L</td>\n",
       "      <td>10k</td>\n",
       "      <td>88</td>\n",
       "      <td>11.8k</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>3.9</td>\n",
       "      <td>52.6k</td>\n",
       "      <td>5.7L</td>\n",
       "      <td>7.8k</td>\n",
       "      <td>22.4k</td>\n",
       "      <td>7.3k</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wipro</td>\n",
       "      <td>3.7</td>\n",
       "      <td>50.2k</td>\n",
       "      <td>4.4L</td>\n",
       "      <td>5.5k</td>\n",
       "      <td>555</td>\n",
       "      <td>5.2k</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3.8</td>\n",
       "      <td>47.2k</td>\n",
       "      <td>5.6L</td>\n",
       "      <td>5.4k</td>\n",
       "      <td>1.5k</td>\n",
       "      <td>6k</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>3.8</td>\n",
       "      <td>38.9k</td>\n",
       "      <td>4.2L</td>\n",
       "      <td>4.7k</td>\n",
       "      <td>1.2k</td>\n",
       "      <td>4.1k</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name ratings reviews salaries interviews   jobs benefits photos\n",
       "0        TCS     3.7   84.3k     8.6L        10k     88    11.8k     87\n",
       "1  Accenture     3.9   52.6k     5.7L       7.8k  22.4k     7.3k     39\n",
       "2      Wipro     3.7   50.2k     4.4L       5.5k    555     5.2k     90\n",
       "3  Cognizant     3.8   47.2k     5.6L       5.4k   1.5k       6k     69\n",
       "4  Capgemini     3.8   38.9k     4.2L       4.7k   1.2k     4.1k     41"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a01c73ff-b6f5-4854-9d81-dfab83b1b8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1a70aba4-5163-46bc-8ea8-0a31e654443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection and saving completed.\n"
     ]
    }
   ],
   "source": [
    "final.to_csv('ambitionbox_companies1.csv', index=False)\n",
    "print(\"Data collection and saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8c56d-12a3-49bf-aeeb-00b8e3f1c0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
